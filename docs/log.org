#+TITLE: Project Log

#+OPTIONS: num:nil
#+OPTIONS: html-postamble:nil

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://gongzhitaao.org/orgcss/org.css"/>

#+LATEX_HEADER: \usepackage[margin=3cm]{geometry}
#+LATEX: \setlength{\parindent}{0pt}
#+LATEX: \setlength{\parskip}{\baselineskip}
#+LATEX_CLASS: article

* Introduction
  This page is a shared log detailing the work the group has done and what
  challenges and problems it has encountered. For the most part, it's updated
  weekly unless some big change happens.

  A time log can be found at Google Sheets: https://bit.ly/2PRKRl8

  The time log has exact tasks worked on each entry, for each member.

* Week 7
** Important info
   We've migrated to a new drive, which means larger storage capacity but also
   means the timelog link has been updated to a new link. Our progress will not
   be updated on the old link so make sure you check the new one!

   Also regarding the time log feedback about members not putting in enough
   time, due to the IT part of our group having more work to do regarding other
   courses, we've opted for them to only work 16h a week until next week. They
   will account for this by working 24h later. We also update the time log every
   Friday so if a week is missing

** Progress
*** Presentation
    We held the half time presentation and were satisfied with it, though we
    still have some problems we want to work out regarding the scope of the
    project.
*** SpecGAN
    All we've done on specGAN this week is to setup training environment and
    checkpointing so that we can train it for a longer period of time.

    Below are some results of training the model on all kinds of guitar sounds
    in the NSynth dataset. Note that this set includes both acoustic and
    electric guitar, which sound very different.

#+DOWNLOADED: file:///home/eethern/Downloads/result.gif @ 2020-03-06 12:41:39
[[file:Week%207/result_2020-03-06_12-41-39.gif]]

    This is a GIF of the training from epoch 0 to epoch ~140. Not much to say other than it looks decent.

#+DOWNLOADED: file:///home/eethern/Downloads/image.png @ 2020-03-06 12:43:03
[[file:Week%207/image_2020-03-06_12-43-03.png]]

    This image show a longer training period, epoch ~640 of a different seed. As you
    can see, the spectrograms here resemble the real ones calculated in week 5. I
    realised I haven't explained how a spectrogram works:

    - X axis is the sample (time in discrete sense)
    - Y is the frequency, or tone if you will
    - Color is the magnitude of the short-term fourier transform

    The straight horizontal lines indicate a frequency or note was played for a long
    time. The reason for many horizontal lines are overtones of the note. These
    overtones should be evenly spaced, if we are trying to simulate a note from an
    instrument. As you can see, the model has far to go in that regard.

    Also note the purple part to the right. The sound samples are 4 seconds long,
    with 64000 samples each but almost all sounds cut out at around 3.2s. That is
    way the purple area exists in each spectrogram.

    I should also mention that this is trained on the valid set of NSynth, meaning
    instead of ~280k samples that the training set has, we are only working with
    ~12k. This is very bad, but the reason has to do with us not being able to load
    in the larger dataset into colab due to some bug that is extremely hard to
    troubleshoot. (Input/output error if you are curious). There is very little info
    online so either we try solving it on our own (no good error log of it) or we
    use other training resources.

    We also have to work on inverting this; there are a lot of parameters that need
    to be specified for this inversion to be done correctly and sound okay.

*** New model proposal by Elias
#+DOWNLOADED: file:///home/eethern/Downloads/MVIMG_20200306_125637.jpg @ 2020-03-06 13:00:04
[[file:Week%207/MVIMG_20200306_125637_2020-03-06_13-00-04.jpg]]

    While SpecGan is good at generating notes, it is not easy to convert an existing note to a latent vector which can be fed to the generator.  This would be useful if we want to train a network to generate melodies as a sequence of latent space vectors.

    The solution proposed here is to make a hybrid of variational autoencoders and gans, such that crisp images can still be generated, but it also becomes possible to encode them.

    The idea is to first train a variational autoencoder, and then train a gan to generate realistic images when given the encoding and some noise as input.
    In order to ensure that the generated images look similar to the input, the GAN generated image is also encoded, and the generator
    gets an additional loss that ensures that the new encoding is similar to the encoding of the original image.

*** Transformer and MIDI
    In the transoformer regard, we are working on getting the MIDI pipeline done
    so that we can train the transformers on midi data. The dataset for this is
    MAESTRO, which includes both raw audio and MIDI of recordings.

    MIDI is great at structure, and the goal of the transformers are to get long
    term structure. Further ahead in the project, we want to combine note
    generation with structure of transformers to hopefully generate music with
    details of raw audio and structure of MIDI.

    So far, there's a lot of research about transformers and how other models
    have encoded MIDI for use with machine learning.

*** Problems
    - *Resources*: Still no reply about resources for training on chalmers. Sent
      another mail asking for a response since it has been a week.
    - *Ambitions and scope of project*: We will discuss this more in the next
      meeting.
    - *Low hours carl*: He has 3 other courses that take his time, which makes
      distributing the hours difficult.

** Summary of each member
   - *Christoffer*: Helped with structuring the presentation. Trained a specGAN to
     generate nice looking images (lots of bug testing and hyperparameter tuning
     in this task). Minor work on transformers (mostly reading about existing
     implementations and how to encode MIDI).
   - *Eric*: Looked at the MIDI format and created a MIDI encoder function that
     can later be used in the dataset preprocessing pipelines. Read about GAN
     training techniques like label smoothing. Read about the MIDI format and
     created a function to encode MIDI files to a format that can be used to
     train a network.
   - *Carl*: Gave up on wavenet (at least for now), currently working on
     preprocessing the MAESTRO dataset)
   - *Lovisa*: Helped a bit with preparing presentation (along with the rest of
     the group), continued work on spectrogram GAN, started working on
     transformers with Elias and Christoffer. Mainly tried to get the Music
     Transformer by Magenta on github to work, as well as collected some
     research relevant to the subject.
   - *Cao*: Worked on the presentation with the group and presented it with Elias.
     Did some light reading about wave2midi2wave.
   - *Elias*: This week I worked on, and presented the half-time presentation with
     cao. Also came up with a new model for encoding and synthesis of high
     quality data samples with untangled, normally distributed, latent
     representations.
** Next week
   - We got the recommendation to just work on implementation, but we have quite
     a bit of things we could add to the report already.
   - Finish encoding MIDI and start experimenting with transformers for structure.
   - Explore the idea described by Elias above
   - Hopefully solve the resource problem

* Week 6
  We spent parts of the week revising the project plan, which is now accepted.
** Project so far
   The goal for the past two weeks have been generating a note. There has been a
   considerable amount of effort put towards this. Below some results are shown
   (hard to show audio, we should try hosting those results somewhere and
   linking to them)

*** WaveRNN
    #+CAPTION: WaveRNN by Deepmind
    #+DOWNLOADED: https://raw.githubusercontent.com/fatchord/WaveRNN/master/assets/tacotron_wavernn.png @ 2020-02-29 11:20:30
    [[file:Week%206/tacotron_wavernn_2020-02-29_11-20-30.png]]


    Eric managed to generate something loosely sounding like a flute using this
    model. Loosely as in it's clearly a wind instrument and it is a recognizable
    note with overtones but it still needs some work/training.

*** SpecGAN
    Unfortuneately, the results from this model look decent, but sound terrible.
    It doesn't quite follow the implementation specGAN used, so that is an area we could improve.

    #+CAPTION: First specGAN generation using 2dConvTranspose layers and 20 epochs with the NSynth dataset.
    #+DOWNLOADED: ~/Projects/course/kandidat/DATX02-20-04/docs/log/Week 6/iVBORw0KGg_2020-02-29_11-15-02.png @ 2020-02-29 11:15:02
    [[file:Week%206/iVBORw0KGg_2020-02-29_11-15-02.png]]

*** WaveNet
    Carl attempted training WaveNet, which when listening could produce both
    sine and square waves.

    #+CAPTION: Example of different wave shapes for reference
    #+DOWNLOADED: https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Waveforms.svg/1280px-Waveforms.svg.png @ 2020-02-29 11:23:23
[[file:Week%206/1280px-Waveforms.svg_2020-02-29_11-23-23.png]]


*** Problems
    *Too ambitions*: The project is very ambitious. The workflow of starting on
    simple tasks (generating a note etc) and building on those with sprints
    remedies that somewhat. Still, we want to spend some time exactly defining
    what the end product will be.

    *Better planning*: We've realised we need a better system for distributing
    tasks to the members. Right now you could easily not know what to work. Our
    idea is to use Trello for this, but that requires setup and splitting tasks
    into even smaller tasks.

    *Resources*: We need better resources for training. We've started asking about
    these things. Hopefully we will get an answer next week.

** Meetings and workshops
   Nothing special, most meetings regarded the project plan, the first
   presentation or just working on the two models explained last week.

** Summary of each member
   - Christoffer: Mostly worked on plan and the specGAN model. Also started a
     bit on final report and helped with presentation. Also been handling
     communication wih examiner and sent mails about computing resources
   - Eric: I started with training an existing model called WaveRNN where I
     managed to generate something that sounds like a flute note. I did the
     training on my personal computer at home which is not optimal. We need
     better computing resources. I then went on to try a model called MelNet,
     which is similar to WaveRNN but it uses melspectograms instead of waveforms
     which might be more promising.
   - Carl: Some work on report; successfully training a WaveNet on sine and
     square waves
   - Lovisa: Project plan work, as well as some on the specGAN
   - Cao: Worked on the presentation, reading about GANSynth, trying out
     different discriminator/ generator for the simple GAN model that I
     implemented last week.
   - Elias: Spent the first half of the week rewriting the project plan.
     Afterwards I primarily worked on getting a 1d convolutional autoencoder
     working. I kind of succeeded, but it is very computationally heavy at the
     moment and the loss doesn’t really decrease. The output is just noise so
     far.

** Next week
   - Presentation on tuesday
   - Tweak/train note generation models
   - Start work on structure models (melody)
   - Begin writing parts of report (note generation)

* Week 5
  We spent this week working on implementing two kinds of models:
  1. WaveNet - a raw audio generative model mainly used for speech synthesis
  2. SpecGAN - a model using generative adversarial networks for training by converting audio into spectrographs.

  The main purpose of this was to generate a note using the NSynth dataset
  (dataset consisting of different notes played on different instruments.

** Project plan review
   After a meeting with our examiner, there were a fair amount of things that
   needed to be changed in the plan.

   Most of the feedback applies to the entire plan, but here are some key points:
   - *Background*: Does not explain or motivate the problem well enough. It is meant to capture the reader but our background lacks a lot of passion required for that.
   - *Aim*: Same here generally, does not explain why this is an important and interesting field.
   - *Timeplan*: Does not tell a story, how will we accomplish these things. Try and detail every week and what happens if we discover hurdles. It also has to detail consistent deliveries, ie if the project suddenly had to stop for whatever reason, what do we have to show for our work?

   Deadline for the rewritten plan is Wednesday, <2020-02-26 Wed> at 12:00. We
   will also try to send it to our supervisor by Monday/Tuesday.

** Project so far
   So far, a lot of work has been going on using colab, a notebook editor in
   Google drive. It allows limited access to GPUs which makes it great for
   smaller experimentation of models. In the future, we'll want to either pay
   for access to GPUs, or try and use Chalmers GPU clusters.

*** WaveNet
    WaveNet requires the amplitudes to be encoded to something that is easier
    for the network to work with. This is done using mu_law encoding, which is
    basically just bucketing the amplitudes, but where is gives mode detail to
    small amplitudes than large ones.

*** SpecGAN
    We were originally going to implement GAN-TTS, but because of its
    complexity, we decided to implement something simpler first. As mentioned,
    most guides on GANs are for images, so it seemed fitting to start with a
    model using images (spectrographs).

    #+CAPTION: Spectrographs for 10 different notes generated
    #+LABEL: fig:week5_
    #+NAME: fig:week5_spec
    [[./img/week5specs.png]]

    This model requires processing the audio waveform into images using digital
    signal processing. This did not have to be done manually, as there are
    plenty of libraries to use, but the challenge is to ensure all images of the
    entire dataset represent the same thing and have the same format and size.
    As such, the data preprocessing has been one of the subtasks for this.

    The other task is to implement the actual model. There are many guides on
    implementing a GAN using the MNIST dataset (dataset consisting of
    handwritten letters in image form), but some slight modifications are
    required to suit our needs.

** Meetings and workshops
   Meetings and workshops were spent working on the two models in groups of
   three people. Working in groups ensures everyone is learning and are helping
   eachother.

** Summary of each member
   - Christoffer: Work on the SpecGAN model, specifically the part of converting the entire NSynth dataset into spectrograph images
   - Eric: Work on preprocessing of data, like using the mu-law algorithm. Also been trying to implement a smaller version of wavenet and learning how to do custom training loops.
   - Carl: Work on implementing wavenet and rendering the model
   - Lovisa: Researched and presented sparse transformers. Also worked on the model implementation parts of SpecGAN
   - Cao: Worked on implementation of the model part of GAN
   - Elias: Research reformer (efficient transformer) and work a lot on wavenet implementation

** Next week
   1. Complete the project plan
   2. Start basic work on project report
   3. Hopefully generate notes with either of the two models being worked on
   4. If time, start investigating using transformers for the structure part of music generation

* Week 4
  Most of this weeks time was spent on planning and writing the project plan.

** Time log warning
  Apparently the expected work amount up to (and including) week 3 was an average of
  72 hours (according to mail sent to supervisor). Unless this is an error, that
  would mean 24 hours worked per week on average. The information we received
  was that it's expected to work 20 hours a week, but that initially that is
  hard to achieve. In case it's not an error, we are aware of it but it doesn't
  match information we've gotten earlier.

** Regarding project log feedback
   I appreciate the feedback regarding the project log but want to explain something.
   So far, most of the work that has been done is either research (paper and
   presentation for group), writing contract/plan or minor implementation.

   I mention this because so far, there's very little to talk about regarding
   individual performance here. We could spend a lot of time detailing
   everything done, but that is much better done in the time log above. The
   point is, up to this point there has been a lot of shared work.

   Now that the planning stage is over (which is a very shared job), this part
   should be easier to write as more individual tasks will be delegated.

** Meetings and workshops
  A meeting with chalmers writing was booked, but since that required two groups
  to sign up, the meeting never went through. We will try to book another one,
  but since the plan now is delivered, getting feedback for it seems unneccesary.

  On wednesday, the first draft was sent to the supervisor, with feedback
  presented to the group on friday morning. The meeting and workshop held on
  friday was primarily spent on refining the plan after the feedback received.
  All in all, the group is happy with how the plan turned out considering the
  project is very open and at a slightly more advanced level than common for
  bachelor theses.

** Project so far
   The project plan is complete. Some initial trial and error has been
   performed, though generating anything close to music is far off. According to
   the timeplan, we are now in the phase of generating a musical note using
   machine learning.

   A issue we currently face seems to be storage space. Datasets take a fair
   amount of space, yet have to be loaded when training. We're currently waiting
   for a reply regarding using Chalmers computing clusters but other options are
   available at a price. The canvas page does not specify whether pricing for
   such clusters are included in the 3000kr budget (as they don't fall under
   components or software), so that will have to be investigated.

** Summary of each member
   We will use this section to detail problemsolving/tasks delegated to members.
   Besides everyone working on the project plan, here are some tasks solved by each member
   - Christoffer: So far been tasked with documentation, project log writing and generally being the secretary. Otherwise been learning tensorflow
   - Eric: Took on the challenge of creating a gantt chart, which he completed by
     writing his own javascript script. Also have been very active in initial
     development and testing of ideas using google colab.
   - Carl: Ensured our latex documents have proper systems for commenting and change requesting, which helped writing the plan immensely.
   - Lovisa: Contacted AIVA (AI music company) for info on how their product worked but didn't get much back from them. Also went through tensorflow guides.
   - Cao: Research autoencoders and attempted implementing and training basic models using Keras and tensorflow
   - Elias: Made an architecture proposal (shown below), which we will look into more next week.

     #+CAPTION: Architecture proposal by Elias
     #+LABEL: fig:week4_prop
     #+NAME: fig:week4_prop
   [[./img/weekproposal.png]]

* Week 3
  As per usual, the week began with a meeting on Tuesday followed by a longer
  workshop. During the meeting, the members went through what they had worked on
  since last friday. For the most part, that was research on tensorflow and a
  paper published by Spotify creator group.

  For the workshop, it was decided that the majority of time
  would be spent on writing the project plan. Basic outlining was conducted to
  ensure everyone was on the same page regarding the content.

  On friday, there was a meeting with the supervisor where the group quickly
  went through some research notes they had taken from the presentations held
  last week. Additionally the focus of this meeting was on the project plan.
  There were a fair amount of criticism of the current rough draft.

  After this meeting, the rest of the day involved a long workshop on writing
  the plan according to the criticism received earlier. A lot was changed and
  this brought the draft much closer to the final writeup.

  There is still work to be done on the plan. The deadline is next friday with
  the groups' deadline being set to Wednesday. Therefore, the next week will
  primarily deal with finishing the project plan.

** Problems encountered
   Because the group is not used to writing a research project plan but rather a
   product project plan, one of the greatest obstacles have been defining what
   will be done. Combined with the wide field, it is difficult to estimate how
   much time each task takes.

   The project task has therefore been simplified a fair bit, but it is still in the
   groups ambition to incorporate the more complex features of the project given
   that there is available time later on.


* Week 2
  The week began with a meeting on tuesday, during which a number of points were brought up
  - Decide report language and register that on canvas
  - Began talk about the project report
  - Discussions on the current writeup of the contract

  The meeting was immediately followed by a workshop, where how to efficiently
  structure out research was determined. we concluded that the
  group would divide into subgroups with the intent of each reading and
  summarizing papers. Machine learning is a wide field, beyond basic concepts,
  learning everything will take away too much time from the actual project.

  After a meeting with the supervisor on friday, a research meeting was held.
  The idea was to take the subgroups determined earlier and have them present
  their findings for the group. This process will be evaluated for future
  research meetings, but we felt it was a good start. If anything, the primary
  goal of them is to spark discussions, which it was very effective at.

  Because Cao only returned on thursday, the contract wasn't sent to our
  supervisor until Friday evening, after the meeting. The contract is now
  considered finished.

  Though stated in last weeks log that we would begin work on the project plan
  this week, small strides were made in that direction. This has a lot to do
  with the very open project description. The primary hurdle is to decide on a
  goal that is not too easy, but realistic enough to achieve. With such a wide
  field and different ways of doing things, we have given that part a bit more time.

  Next week will be focused on the project plan and another research meeting.

* Week 1
  Since this is the first week of the project, the majority of it has been
  discussing the project and reading up on research papers. We started the week
  by attending the introductory seminars.

  During the three meetings, we set up a slack group, had our first meeting with the supervisor and
  started writing the group contract.

  Alone, most of us studied research papers. Since some of the members lacked
  experience in the field, Elias set up a notebook intended for teaching the
  basics.

  For personal reasons, Cao was absent for part of the week, but this was notified well in advance.

  For next week, we are looking to finish the group contract, continue researching and starting work on the project plan.
